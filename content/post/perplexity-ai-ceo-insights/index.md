+++
title = "Perplexity AI: Insights from the CEO Aravind Srinivas"
description = "Insights from Lex Fridman's interview with Aravind"
date = "2024-06-27T20:21:42-07:00"
draft = false
tags = ["AI", "tech-explorations", "LLM"]
topics = []
+++

Last week, I watched an interview of [Aravind Srinivas](https://www.linkedin.com/in/aravind-srinivas-16051987/), the CEO of **Perplexity AI** (https://www.perplexity.ai). It is a three-hour interview done by [Lex Fridman](https://www.linkedin.com/in/lexfridman/) where Aravind talked about the major breakthroughs in AI that brought us to LLMs, the mission of Perplexity, how the technology works, his vision of the future of search and web in general, and some valuable advice for startup founders and young people.

[Fascinating interview](https://www.youtube.com/watch?v=e-gwvmhyU7A) - highly recommended for everyone to watch. Personally, it opened my eyes to the fact that Perplexity is very different from other chatbots - not only in how it works, but what it is trying to solve. So I started using it for a few days and was blown away by the results ðŸ’¯. I realized that this is one of the tools that gives you so much value that you cannot imagine going back to the way of doing it. 

In this post, I would like to share the insights I learned from the interview and how it inspired me to know more about the future of Search. 

## Context - about Perplexity
Perplexity is an AI search (answer) engine that answers questions only based on **factual, real-time data** retrieved from trusted sources. Every answer it returns has the relevant sources as citations. When you ask a question, it doesn't give you a bunch of links like Google does, nor does it give just a potentially unreliable answer like most of the LLMs. Instead, it gives a concise answer based on grounded factual truth along with the links to the sources of that answer so that you can do the fact checking yourself.

## Insights from the interview

To know more about Perplexity, refer to my previous post here - [Perplexity AI](/post/perplexity-ai)
 
 The following sections describe the key insights from the interview. Note that all of this information is from my own personal notes captured while watching the interview (twice!), and not generated by an LLM.

 ## AI breakthroughs so far
 * When asked how Perplexity is planning to take on Google, Aravind said 'we don't have to. We are doing what Google doesn't want to do - i.e. go after the content or link clicks that are not profitable to them. He refers to this quote attributed to Jeff Bezos - *Make the weakness of your enemy your friend*.
 * Yann LeCun was right when he said in 2016 - when Reinforcement Learning was all the rage - he said RL will NOT be the most important thing for long. It is only a cherry on the cake and the real cake is unsupervised learning on which you apply supervised learning as an add-on. This is exactly the recipe of ChatGPT where the bulk of the compute is spent on pre-training (the cake), followed by supervised fine-tuning and instruction following (the icing), followed by the RLHF (Reinforcement Learning from Human Feedback) which is the cherry at the very top.
 * He gave a detailed history of LLMs and reminded that the famous "Attention Is All You Need" paper published in 2017 was built on top of several preceding research papers such as '[Neural machine Translation and Self Attention](https://arxiv.org/abs/1409.0473)' in 2014 and [PixelRNNs](https://arxiv.org/abs/1601.06759) in 2016 by DeepMind which introduced the Wavenet architecture.
 * He emphasizes that Perplexity's goal is to never hallucinate, which was an interesting remark. We have all become used to the fact that the LLMs will hallucinate, so it was good to hear someone say the opposite as their main goal. His uber point was that the possible areas of hallucination are in the context understanding, or picking the wrong source or outdated information.
 * If we look at the current LLMs, we are spending a lot of time on compute, which seems brute force approach. We want a system that can learn like an open book exam, i.e. it can retrieve relevant information at the time of inference, rather than memorizing everything.
 * The large models are intelligent, but we as humans are able to extract only part of their intelligence available through talking to them in natural language. There is a lot of intelligence compressed in their multi-billion parameters.

## The future of AI, Search and Web
* When Lex asked what is the future of search, Arvind said it is not better or faster search, it is **discovery of knowledge**.  Imagine a world where everyone can do that and fact check any information for themselves. I want that! If done right, tools like Perplexity will definitely help us do that.
* In a good knowledge discovery system, the journey doesn't end when you get an answer; it begins *after* you get the answer. Maybe the answer was not good enough, or you want to go deep.
* AGI will be limited by **inference compute**, not compute for pre-training or post-training.
* The biggest risk of AI is not about AI going rogue and taking over the world. It is also not about who has access to the model weights. It is really about who has access to the compute - it risks concentrating power in a few individuals, corporations or states.

### The provocation
* Is there a way to decouple reasoning and facts? Can we build a small language model that has a good level of common sense reasoning and can be applied iteratively such that it bootstraps its own reasoning? Microsoft is trying to pursue this path with their Phi models where they are taking the tokens of GPT-4 on the datasets that require reasoning and train the model on that dataset only. 
* Even if it couldn't arrive at an answer, if it was given a right hint, it can reason about what would have been the right answer. In essence, the model becomes the reasoner of itself
* If getting better at math or coding translates to greater reasoning abilities on a vast array of tasks, it could enable us to build agents too.
* Imagine you can have a conversation with an AI where you feel like talking to Einstein or Feynman. You ask it a hard question like 'invent the drug for cancer'. It says that it doesn't know right now and it starts thinking. It thinks for a while, bootstraps the reasoning using the facts known to it, thinks for a while and on and on, and finally after a week or so it comes back with an answer. If we can do this, it will be a breakthrough in the direction of AGI.

### Advice to startup founders and young people
* If you make your mission or purpose about someone else, you are aiming too low. You must make it bigger than you and the people in your company.
* Conventional wisdom about success is correct - relentless determination and grit are crucial to succeed in any area.
* One mistake that some founders make is that they work on the thing that market wants and thus rely on the immediate dopamine hits of user engagement or money. This makes it hard to get through tough moments and persevere. Instead, you should work on something that is **important to you**, something that YOU care about. You need to know what your dopamine hits are.
* Doing anything great requires commitment and dedication. You should be doing the work because it matters, not to make money only.
* About work life balance, some people don't want to work hard and that's ok. I don't intend to say that a life without hard work is meaningless. But if there is an idea that occupies your mind all the time, then it is worth making your life about that idea, especially early in your career because it gives you more freedom to explore and learn deeply.
* Hang out with people who are driving and guiding you to be better. A good quote attributed to Messi - *I worked hard for decades to become an overnight hero*.

## My favorite
What makes human special is that we are creatures of curiosity. We need to expand on that and discover more knowledge using the power of AI. Internet started off to disseminate knowledge. It evolved to organize topics (Yahoo!), organize information (Wikipedia), organize links (Google). Now we have tools like LLMs and Perplexity to get deeper answers, so we can ask new kind of questions. If we can empower every person to be more truth-seeking than before, because they are able to do and they have the tools to do so, then it will lead to a better world. More people will be interested in fact checking themselves than relying on others to do so.

I really enjoyed this interview and learned a lot from it. As a side note, about the quote attributed to Messi, I asked Perplexity who said this quote and it said *Ray Kroc, the businessman who built McDonald's into a global franchise, is quoted as saying: "I was an overnight success all right, but thirty years is a long, long night."*. Fact checking at our finger tips! I love it.

The End!